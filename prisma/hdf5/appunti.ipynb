{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# appunti hdf5\n",
    "\n",
    "formato per scambio di dati autodescrittivi \n",
    "\n",
    "autodescrittivo: data set, eg array n dimensionale di numeri, ha metadati addizionali associati ad esso che descrivono cose come rango \n",
    "\tdell'array, numero di elementi in ogni dimensione, etc\n",
    "\t\n",
    "prende principi da programmazione orientata agli ogg\n",
    "\n",
    "array n-dim, immagini e tabelle possono esser immagazzinati nello stesso file ma in oggetti diversi\n",
    "\n",
    "utente può capire contenuti del file a cui accede nei termini dei vari tipi di dati oggetto hdf5, segue descriz tipi dati oggetto\n",
    "\n",
    "## hdf5 file struct\n",
    "\n",
    "file hdf5 = directory + collection di data obj\n",
    "\n",
    "ogni data obj ha un entry nella directory contenente puntatore a locazione del data obj, e informazione sul datatype\n",
    "\n",
    "++ su datatypes: https://portal.hdfgroup.org/display/HDF5/Datatype+Basics\n",
    "\n",
    "ci sono solo due data obj fondamentali in hdf5: groups e namespaces\n",
    "\n",
    "file hdf5 sono organizzati gerarchicamente con due strutture primarie: groups, datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#= non va\n",
    "# grafo creato con ipytree\n",
    "# installazione : dal prompt di comandi di anaconda: conda install -c conda-forge ipytree\n",
    "using PyCall\n",
    "py\"\"\"\n",
    "def pytree():\n",
    "    from ipytree import Tree, Node\n",
    "    tree=Tree()\n",
    "\n",
    "    tree.add_node(Node(\"Node1\"))\n",
    "    tree.add_node(Node(\"Node2\"))\n",
    "    tree.add_node(Node(\"Node3\"))\n",
    "\n",
    "    tree\n",
    "\"\"\"\n",
    "mytree= py\"pytree\"\n",
    "mytree()\n",
    "=# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gruppi\n",
    "\n",
    "un gruppo hdf5 è una struttura contenente 0 o + oggetti\n",
    "\n",
    "ogni gruppo contiene 2 parti: \n",
    "\n",
    "    . header: contiene nome gruppo, lista di attributi del gruppo\n",
    "    \n",
    "    . tabella simboli: lista tutti gli oggetti hdf5 appartenenti al gruppo\n",
    "    \n",
    "gerarchia gruppi/membri è simile a directory/file e path in UNIX:\n",
    "\n",
    "/ <- indica gruppo root\n",
    "\n",
    "/foo <- indica membro foo del gruppo root\n",
    "\n",
    "/foo/loo <- indica membro loo del gruppo foo, il gruppo foo è membro del gruppo root\n",
    "    \n",
    "## dataset\n",
    "\n",
    "dataset sono array multidimensionali di dati con metadati annessi, un dataset è immagazzinato in due parti: header e data array\n",
    "\n",
    "### dataset header\n",
    "\n",
    "contiene informazioni necessarie all interpretazione della porzione array del dataset e metadati(o puntatori a metadati)  che descrivano o annotino il dataset.\n",
    "\n",
    "informazioni nell'header includono: nome dell oggetto, dimensioni oggetto, number-type dell oggetto, info su come i dati stessi sono salvati a disco e *** altre informazioni usate dalla lib per velocizzare accesso dati *** o garantirne integrità\n",
    "\n",
    "ci son 4 classi di info in ogni header:\n",
    "\n",
    "1. nome <- sequenza di caratteri ascii alfanumerici\n",
    "2. datatype <- descrive disposizione specifica dei bit del dataset, è immutabile, ci sono due categorie di datatype: dt atomico e dt composto\n",
    "    \n",
    "    2.1. datatype atomico: ogni datatype atomico appartiene a una determinata classe e possiede determinate caratteristiche come dimensioni, ordine, precisione e offset. *** documento considera solo alcune di queste caratteristiche ***    \n",
    "    classi atomiche includono integer, float, data/ora, string, bit field, opaque\n",
    "    proprietà integer includono dimensioni, endianità, firmatura(se il dato è stato firmato o no)\n",
    "    proprietà float includono dimensioni e locazione di esponente e mantissa, locazione bit di segno\n",
    "    maggior parte delle app usano datatype predefiniti supportati dai loro compilatori, questi dt sono chiamati datatype nativi\n",
    "    per aumentare portabilità, app dovrebbero quasi sempre usare la designazione NATIVE per descrivere valori dato in memoria.\n",
    "    architettura nativa ha nomi base che non seguono le stesse regole degli altri, nomi di tipi nativi sono simili a nomi di tipo in C\n",
    "    \n",
    "    2.2. datatype composti: collection di dt semplici, rappresentati in unità singola (simile a struct in C).\n",
    "    parti di un dt composto si chiamano membri, i membri di un dt composto posson esser di qualsiasi dt, incluso altro dt composto. $ \\grave{E} $ possibile lettura singola di un membro senza leggere il resto del dt composto.\n",
    "    in genere ogni dataset ha il proprio datatype ma si può usare un named datatype per condividere datatype tra + dataset.\n",
    "    named dt è immagazzinato nel file indipendentemente da ogni dataset ed è referenziato da ogni dataset che seguono quel tipo.\n",
    "    named dt possono avere una lista attributi\n",
    "    NB: named datatype => committed datatype, han cambiato terminologia\n",
    "    @ hdf5 user guide https://portal.hdfgroup.org/display/HDF5/HDF5+User+Guides p18, p173+\n",
    "    \n",
    "\n",
    "3. dataspace <- descrive dimensionalità del dataset, le dimensioni di un dataset possono essere fisse o illimitate (quindi estendibili), è una lista di dimensioni con le grandezze correnti e massime(se dataset illimitato gradezza massima è settata al valore dato dalla variabile interna H5P_UNLIMITED), contiene anche rango(numero di dimensioni) del data array.\n",
    "    dataspace può definire partizioni dati per poter svolgere operazioni di i/o solo su parti selezionate\n",
    "    dato un dataset n-dimensionale si possono fare selezioni parziali in 4 modi: selezionando hyperslab n-dimensionali logicamente contigui, seleziona hyperslab non logicamente contigui consistenti di blocchi d elementi(hyperslab) equidistanti, seleziona un unione di hyperslab, seleziona lista di punti indipendenti\n",
    "    hyperslab: hyperslab in hdf5 è un pattern rettangolare definito da 4 array  \n",
    "    vedi anche http://davis.lbl.gov/Manuals/HDF5-1.8.7/UG/12_Dataspaces.html         \n",
    "    https://support.hdfgroup.org/HDF5/Tutor/select.html per tutorial\n",
    "    \n",
    "| Parametro\t| Descrizione |\n",
    "|---|---|\n",
    "| Offset\t| The starting location for the hyperslab.| \n",
    "| Stride\t| The number of elements to separate each element or block to be selected.| \n",
    "| Count\t| The number of elements or blocks to select along each dimension.| \n",
    "| Block\t| The size of the block selected from the dataspace.| \n",
    "    \n",
    "4. storage layout <- continuo per default (salvato linearmente allo stesso modo di come viene organizzato in memoria)\n",
    "    esistono 2 altri layout definit al momento in hdf5: \n",
    "        . compact: usato quaqndo l'ammontare di dati è piccolo da poter esser immagazzinato direttamente nell'object header\n",
    "        . chunked: divisione del dataset in pezzi equidimensionali salvati separatamente, ha tre benefici:         \n",
    "            1. permette buona performance quando si accede a sottoinsiemi dei dataset, anche quando sottoinsieme da sciegliere è ortogonale al normale accesso del dataset.\n",
    "            2. permette di comprimere dataset grandi pur mantenendo buone prestazioni quando si accede a parti del dataset\n",
    "            3. permette di aumentare efficientemente le dimensioni del dataset in ogni direzione\n",
    "            \n",
    "            \n",
    "## attributi HDF5\n",
    "\n",
    "un attributo hdf5 è un piccolo dataset con nome che può essere allegato a dataset primari, gruppi o named datatype\n",
    "è un piccolo oggetto di metadati che descrive natura o uso previsto di un oggetto dati primario.\n",
    "è diviso in due parti: nome, value(che contiene data entry dello stesso data type)\n",
    "\n",
    "gli attribvuti son assunti molto piccoli quindi son sempre  storati nell'header dell oggetto a cui si riferiscono. attributi hdf5 sono quindi gestiti tramite interfaccia di attribuyti speciale: H5A, ideata per allegare facilmente attributi a data obj primary come dataset di metadati e a minimizzare requisiti di storaggio.\n",
    "attributi, per l'accesso, possono essere identificati tramite nome o indice. uso di indice permette di iterare tutti gli attributi di un determinato data object.     \n",
    "     \n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "++ hdf5 vs hdf-eos5? hdf-eos5 è estensione hdf per earth observing system def da nasa, definisce 4 datatype nuovi: point, swath, grid, zonal average (@p257 prisma product specification)\n",
    "\n",
    "++ toolkit hdf eos : https://hdfeos.org/software/library.php\n",
    "\n",
    "++ sunto contenuto prodotti dei 3 livelli del prisma http://prisma-i.it/index.php/en/data-access/89-data-access/115-prisma-data-access-description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.1",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
