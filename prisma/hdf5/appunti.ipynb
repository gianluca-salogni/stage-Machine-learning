{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# appunti hdf5\n",
    "\n",
    "formato per scambio di dati autodescrittivi \n",
    "\n",
    "autodescrittivo: data set, eg array n dimensionale di numeri, ha metadati addizionali associati ad esso che descrivono cose come rango \n",
    "\tdell'array, numero di elementi in ogni dimensione, etc\n",
    "\t\n",
    "prende principi da programmazione orientata agli ogg\n",
    "\n",
    "array n-dim, immagini e tabelle possono esser immagazzinati nello stesso file ma in oggetti diversi\n",
    "\n",
    "utente può capire contenuti del file a cui accede nei termini dei vari tipi di dati oggetto hdf5, segue descriz tipi dati oggetto\n",
    "\n",
    "## hdf5 file struct\n",
    "\n",
    "file hdf5 = directory + collection di data obj\n",
    "\n",
    "ogni data obj ha un entry nella directory contenente puntatore a locazione del data obj, e informazione sul datatype\n",
    "\n",
    "++ su datatypes: https://portal.hdfgroup.org/display/HDF5/Datatype+Basics\n",
    "\n",
    "ci sono solo due data obj fondamentali in hdf5: groups e namespaces\n",
    "\n",
    "file hdf5 sono organizzati gerarchicamente con due strutture primarie: groups, datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#= non va\n",
    "# grafo creato con ipytree\n",
    "# installazione : dal prompt di comandi di anaconda: conda install -c conda-forge ipytree\n",
    "using PyCall\n",
    "py\"\"\"\n",
    "def pytree():\n",
    "    from ipytree import Tree, Node\n",
    "    tree=Tree()\n",
    "\n",
    "    tree.add_node(Node(\"Node1\"))\n",
    "    tree.add_node(Node(\"Node2\"))\n",
    "    tree.add_node(Node(\"Node3\"))\n",
    "\n",
    "    tree\n",
    "\"\"\"\n",
    "mytree= py\"pytree\"\n",
    "mytree()\n",
    "=# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gruppi\n",
    "\n",
    "un gruppo hdf5 è una struttura contenente 0 o + oggetti\n",
    "\n",
    "ogni gruppo contiene 2 parti: \n",
    "\n",
    "1. header: contiene nome gruppo, lista di attributi del gruppo\n",
    "\n",
    "2. tabella simboli: lista tutti gli oggetti hdf5 appartenenti al gruppo\n",
    "    \n",
    "gerarchia gruppi/membri è simile a directory/file e path in UNIX:\n",
    "\n",
    "/ <- indica gruppo root\n",
    "\n",
    "/foo <- indica membro foo del gruppo root\n",
    "\n",
    "/foo/loo <- indica membro loo del gruppo foo, il gruppo foo è membro del gruppo root\n",
    "    \n",
    "## dataset\n",
    "\n",
    "dataset sono array multidimensionali di dati con metadati annessi, un dataset è immagazzinato in due parti: header e data array\n",
    "\n",
    "### dataset header\n",
    "\n",
    "contiene informazioni necessarie all interpretazione della porzione array del dataset e metadati(o puntatori a metadati)  che descrivano o annotino il dataset.\n",
    "\n",
    "informazioni nell'header includono: nome dell oggetto, dimensioni oggetto, number-type dell oggetto, info su come i dati stessi sono salvati a disco e ** altre informazioni usate dalla lib per velocizzare accesso dati ** o garantirne integrità\n",
    "\n",
    "ci son 4 classi di info in ogni header:\n",
    "\n",
    "1. nome <- sequenza di caratteri ascii alfanumerici\n",
    "2. datatype <- descrive disposizione specifica dei bit del dataset, è immutabile, ci sono due categorie di datatype: dt atomico e dt composto\n",
    "    \n",
    "    1. datatype atomico: ogni datatype atomico appartiene a una determinata classe e possiede determinate caratteristiche come dimensioni, ordine, precisione e offset. ** documento considera solo alcune di queste caratteristiche **\n",
    "        classi atomiche includono integer, float, data/ora, string, bit field, opaque. \n",
    "        proprietà integer includono dimensioni, endianità, firmatura(se il dato è stato firmato o no).\n",
    "        proprietà float includono dimensioni e locazione di esponente e mantissa, locazione bit di segno.\n",
    "        maggior parte delle app usano datatype predefiniti supportati dai loro compilatori, questi dt sono chiamati datatype nativi per aumentare portabilità, app dovrebbero quasi sempre usare la designazione NATIVE per descrivere valori dato in memoria. \n",
    "        architettura nativa ha nomi base che non seguono le stesse regole degli altri, nomi di tipi nativi sono simili a nomi di tipo in C\n",
    "    \n",
    " 2. datatype composti: collection di dt semplici, rappresentati in unità singola (simile a struct in C).\n",
    "    parti di un dt composto si chiamano membri, i membri di un dt composto posson esser di qualsiasi dt, incluso altro dt composto. $ \\grave{E} $ possibile lettura singola di un membro senza leggere il resto del dt composto.\n",
    "    in genere ogni dataset ha il proprio datatype ma si può usare un named datatype per condividere datatype tra + dataset.\n",
    "    named dt è immagazzinato nel file indipendentemente da ogni dataset ed è referenziato da ogni dataset che seguono quel tipo.\n",
    "    named dt possono avere una lista attributi\n",
    "    NB: named datatype => committed datatype, han cambiato terminologia\n",
    "    @ hdf5 user guide https://portal.hdfgroup.org/display/HDF5/HDF5+User+Guides p18, p173+\n",
    "    \n",
    "\n",
    "3. dataspace <- descrive dimensionalità del dataset, le dimensioni di un dataset possono essere fisse o illimitate (quindi estendibili), è una lista di dimensioni con le grandezze correnti e massime(se dataset illimitato gradezza massima è settata al valore dato dalla variabile interna H5P_UNLIMITED), contiene anche rango(numero di dimensioni) del data array.\n",
    "    dataspace può definire partizioni dati per poter svolgere operazioni di i/o solo su parti selezionate.\n",
    "    dato un dataset n-dimensionale si possono fare selezioni parziali in 4 modi: \n",
    "        1. selezionando hyperslab n-dimensionali logicamente contigui, \n",
    "        2. seleziona hyperslab non logicamente contigui consistenti di blocchi d elementi(hyperslab) equidistanti, \n",
    "        3. seleziona un unione di hyperslab, \n",
    "        4. seleziona lista di punti indipendenti\n",
    "    hyperslab: hyperslab in hdf5 è un pattern rettangolare definito da 4 array  \n",
    "    vedi anche http://davis.lbl.gov/Manuals/HDF5-1.8.7/UG/12_Dataspaces.html         \n",
    "    https://support.hdfgroup.org/HDF5/Tutor/select.html per tutorial\n",
    "    \n",
    "| Parametro\t| Descrizione |\n",
    "|---|---|\n",
    "| Offset\t| The starting location for the hyperslab.| \n",
    "| Stride\t| The number of elements to separate each element or block to be selected.| \n",
    "| Count\t| The number of elements or blocks to select along each dimension.| \n",
    "| Block\t| The size of the block selected from the dataspace.| \n",
    "    \n",
    "4. storage layout <- continuo per default (salvato linearmente allo stesso modo di come viene organizzato in memoria)\n",
    "    esistono 2 altri layout definit al momento in hdf5: \n",
    "    1. compact: usato quaqndo l'ammontare di dati è piccolo da poter esser immagazzinato direttamente nell'object header\n",
    "    2. chunked: divisione del dataset in pezzi equidimensionali salvati separatamente, ha tre benefici:         \n",
    "        1. permette buona performance quando si accede a sottoinsiemi dei dataset, anche quando sottoinsieme da sciegliere è ortogonale al normale accesso del dataset.\n",
    "        2. permette di comprimere dataset grandi pur mantenendo buone prestazioni quando si accede a parti del dataset\n",
    "        3. permette di aumentare efficientemente le dimensioni del dataset in ogni direzione\n",
    "\n",
    "            \n",
    "## attributi HDF5\n",
    "\n",
    "un attributo hdf5 è un piccolo dataset con nome che può essere allegato a dataset primari, gruppi o named datatype\n",
    "è un piccolo oggetto di metadati che descrive natura o uso previsto di un oggetto dati primario.\n",
    "è diviso in due parti: nome, value(che contiene data entry dello stesso data type)\n",
    "\n",
    "gli attribvuti son assunti molto piccoli quindi son sempre  storati nell'header dell oggetto a cui si riferiscono. attributi hdf5 sono quindi gestiti tramite interfaccia di attribuyti speciale: H5A, ideata per allegare facilmente attributi a data obj primary come dataset di metadati e a minimizzare requisiti di storaggio.\n",
    "attributi, per l'accesso, possono essere identificati tramite nome o indice. uso di indice permette di iterare tutti gli attributi di un determinato data object.     \n",
    "     \n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "++ sunto contenuto prodotti dei 3 livelli del prisma http://prisma-i.it/index.php/en/data-access/89-data-access/115-prisma-data-access-description "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hdf-eos5\n",
    "hdf-eos5 è un estensione a hdf che stabilisce standard per storare dati eos(earth observing system) ed aggiunge 4 datatypes\n",
    "ogni datatype nuyovo è combinazione di datatype hdf5 standard ed è  servito da una api propria.\n",
    "la libreria hdf-eos5 è la somma di queste API\n",
    "\n",
    "EDF-EOS5 estende HDF5 dando le seguenti features:\n",
    "\n",
    "1. un modo per immagazzinare dati geolocati in remote sensing missions definendo 4 datatipi nuovi composti di oggetti hdf5 standard:\n",
    "    1. Point interface: per dati con informazioni geolocate annesse ma che non hanno organizzazione spaziale o temporale ben definita\n",
    "    2. Swath interface: per data ordinata nel tempo come satellite swath(serie di scanlines ordinate nel tempo) o profilers\n",
    "    3. Grid interface: per dati organizzati in maniera rettilinea su proiezione ben definita e supportata esplicitamente\n",
    "    4. Zonal Average interface: per dati non associati a informazioni geolocate specifiche\n",
    "\n",
    "2. un modo per fornire servizi di search su tutto il sistema: software di operazione scrive metadati speciali che riassumono informazioni spaziotemporali, qualità e stato di produzione dei dati prodotti. \n",
    "    l'insieme completo dei metadati è scritto nei file prodotto in un attributo globale come blocco testo continuo. ovvero i vari campi non son scritti come attributi singoli ma il totale di tutti i campi è scritto come singolo attributo\n",
    "    \n",
    "3. 4 nuovi tipi di attributo\n",
    "    1. attributi globali: si riferiscono a tutto il contenuto del file hdf5\n",
    "    2. attributi oggetto: si riferiscono ad un oggetto specifico\n",
    "    3. attributi gruppo: si riferiscono ad un gruppo specifico\n",
    "    4. attributi locali: sono attributi di campo riferiti a un campo dati (data field)\n",
    "    \n",
    "## datatipo Swath\n",
    "\n",
    "il PRISMA  cattura immagini in maniera pushbroom raccogliendo informazioni(scan lines) ordinate temporalmente su un campo di vista che si muove lungo una direzione(traccia) perpendicolare alle scan line stesse.\n",
    "il dt swath è ideato per storare informazioni di questo tipo quindi il livello1 usa questo dt per raccogliere esprimere dati\n",
    "\n",
    "lo scopo del dt swath è il mappare dati scientifdici a punti specifici sulla superficie della terra. lo swath consiste di 4 parti: \n",
    "\n",
    "1. data fields: parte principale degli swath dal punto di vista scientifico. contengono generamente dati grezzi (spesso contatori) presi dal sensore o parametri derivati da quei dati su base personale del valore. tutti gli altri dati dello swath servono o a fornire informazioni su data field o a supportare particolari tipi di accesso ad essi. sono generalmente array con 1-8 dimensioni, in genere 2. possono essere in qualsiasi tipo di C\n",
    "2. campi di geolocazione: permettono allo swath di essere localizzato precisamente rispetto alla supoerfice della terra. per far ciò l'iterfaccia swath richiede la presenza di coppie di campi longitudinali/latitudinali (\"Latitude\" e “Longitude”), questi campi possono essere in una o due dimensioni ed avere qualiasi tipo\n",
    "3. dimensioni: le dimensioni definiscono gli assi deicampi dati e geolocazione dandogli nome e grandezze. ogni asse di ogni campo dati/geoloc deve quindi avere un campo dimensione associato\n",
    "4. mappe di dimensione: definiscono, uno a uno, la relazione tra ogni dimensione di ogni campo geoloc con la dimensione corrispettiva in ogni campo dati. quando le dimenisoni di dati e geoloc differiscono, la relazione tra essi è definita da campi offset e increment\n",
    "\n",
    "in hdf-eos5 è anche supportata la spezzettatura degli swath, cosa necessaria alla definizione di swath estendibili"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "++ toolkit hdf eos : https://hdfeos.org/software/library.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "++ intro a hdf5 http://davis.lbl.gov/Manuals/HDF5-1.8.7/H5.intro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.1",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
